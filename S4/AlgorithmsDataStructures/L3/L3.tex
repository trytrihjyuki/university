\documentclass{article}
\usepackage[utf8x]{inputenc}
\usepackage{polski}
\usepackage{pythonhighlight}

\usepackage{amssymb, amsmath, amsfonts, amsthm, cite, mathtools, enumerate, rotating, hyperref,pdfpages}
\newcommand \eq[1]{\begin{equation} \begin{split}  #1 \end{split} \end{equation}}


\makeatletter
\newcommand\tab[1][1cm]{\hspace*{#1}}
\def\@seccntformat#1{%
  \expandafter\ifx\csname c@#1\endcsname\c@section\else
  \csname the#1\endcsname\quad
  \fi}
\makeatother

\newtheorem{lemma}{Lemat}
\newtheorem{theorem}{Twierdzenie}

\title{AiSD L3}
\date{31.03.2021}
\author{Maurycy Borkowski}
\begin{document}
\maketitle
\subsection*{zadanie 1}
\begin{python}
def gcd(a,b):
    if b > a:
        swap(a,b)
    if a == b:
        return a
    if min(a,b) == 1:
        return 1

    if a%2 == 0 and b%2 == 0:
        return 2*gcd(a/2,b/2)
    if a%2 == 1 and b%2 == 0:
        return gcd(a,b/2)
    if a%2 == 0 and b%2 == 1:
        return gcd(a/2,b)
    if a%b == 1 and b%2 == 1:
        return gcd((a-b)/2,b)
\end{python}
Poprawność algorytmu wynika z poprawności danej własności.\\\\
Zauważmy, że z każdym wywołaniem rekurencyjnym conajmniej jedna z liczb maleje dwukrotnie, zatem w pesymistycznym przypadku będziemy mieli $\mathcal{O}(\log{a} + \log{b}) = \mathcal{O}(\log{ab})$ Tak samo jak alg. Euklidesa\\\\
% Weźmy dowolne $a$ i $b$ takie, że $a > b$. Wtedy:\\
% $gcd(a, b) = gcd(b, c)$, gdzie $c =a \mod b$\\
% $gcd(b, c) = gcd(c, d)$, gdzie $d =b \mod c$\\
% Wiemy, że $b = k\cdot c + d \geq c + d$, a $a > b \geq c+d$, więc $a+b \geq 2(c+d)$ Widzimy, że po każdych dwóch wywołaniach suma $a+b$ zmniejsza się dwukrotnie, więc dojdzie do maksymalnie $2log(a+b)$ wywołań. Zatem algorytm Euklidesa ma złożoność $O(log(a+b)) = O(log(a+a)) = O(log(a))$
% \subsection*{zadanie 2}
\clearpage
\subsection*{zadanie 3}
Będziemy chcieli połączyć dwie pary wierzchołków otoczek $C_1, C_2$ na \textit{górze} i \textit{dole} tak by powstała otoczka.\\
Możemy to zrobić łącząc najbliższe (skrajne wewnętrzne) punkty otoczek $C_1,C_2$ i później \textit{wspinając} się z tym odcinkiem, dopóki nie będziemy mieli otoczki, tj. będą kąty wklęsłe.\\
\includegraphics[scale=0.6]{convex_tangent}\\
Otrzymujemy algorytm:
\begin{python}
L = wewnetrzne(C1,C2)
while flag:
    flag = False
    while przecina(L, C1):
        przesun_wyzej(L, C1)
    while przecina(L, C2):
        flag = True
        przesun_wyzej(L, C2)
\end{python}
Funkcję $przecina(L,C)$ możemy zaimplementować korzystając z iloczynu wektorowego, dokładnie jego znaku, który określa nam skrętność, używając punktów określających $L$ w obu otoczkach i ich następników.\\\\
$przesun\_wyzej$ przesuwa punkt wyżej w danej otoczce: $v = C[(idx+1)\%n]$\\
Analogicznie znajdujemy odcinek na dole otoczek.\\
\subsection*{Poprawność}
Otrzymujemy wielokąt wypukły, odcinki łączące $C_1, C_2$ nie przecinają ich (dopiero wtedy kończymy pętlę).\\
$C_1, C_2$ zawierają wszystkie punkty, więc zbiór w którym obie się one zawierają też zawiera wszystkie punkty.\\
\clearpage
\subsection*{zadanie 4a}
Na początku zmodyfikujmy (liniowo) nasze drzewo tak aby każdy wierzchołek $v$ miał $deg(v) \leq 3$. Zrobimy to dodając czarne wierzchołki (czerwone = oryginalne z drzewa) z zerowymi krawędziami w następujący sposób:\\
\includegraphics[scale=1.2]{czarne}\\
każdego nadmiarowego syna podpinamy do nowego czarnego którego łączymy z poprzednim czarnym wierzchołkiem.\\
Zerowe krawędzie gwarantują nam, że w tak zmodyfikowanym drzewie rozwiązanie się nie zmieni.\\\\
Korzystamy z metody \textit{Dziel i Zwyciężaj} dla danego wierzchołka $u$ i jego conajwyżej trzech poddrzew $T_1,T_2,T_3$ o korzeniach (sąsiadach $u$) $r_1,r_2,r_3$, odpowiedź to ścieżki wewnątrz każdego z poddrzew $T_i$, ścieżki pomiędzy poddrzewami $T_i, T_j$ (i ścieżki pomiędzy $T_i$ a $u$).\\
Dla danych $i,j$ ($i<j$) oznaczmy przez $w = d(u,r_i) + d(u,r_j)$, $A = v, v \in {T_i}$, $B = w, w \in T_j$. W $A,B$ trzymamy tylko czerwone wierzchołki.\\$A,B$ sortujemy po odległościach wierzchołków od korzeni np. $A$ po $d(v,r_i)$.\\\\
Teraz szukamy takich par $x,y, x\in A, y \in B$, że $d(x,r_i) + d(y,r_j) = D - w$\\
Możemy to zrobić w czasie liniowym (po wcześniejszym sortowaniu $A,B$) idąc od lewej w $A$ i od prawej w $B$.\\
Oszacujmy, złożoność takiego algorytmu:
$$
T(n) = \mathcal{O}(n\log{n}) + T(n_1) + T(n_3) + T(n_3)
$$
Aby złożoność nam nie wybuchła musimy jeszcze zadbać o to by rozmiary drzew wywołania rekurencyjnych były ograniczone lepiej niż $n$. \\Bo wiemy, że $n_1 + n_2 + n_3 = n-1$ w przeciwnym przypadku być może wykonamy $n$ wywołań otrzymując złożoność $\mathcal{O}(n^2\log{n})$.\\
Możemy to osiągnąć biorąc jako wierzchołek do usunięcia $u$ centroid obecnego drzewa, wtedy $n_i \leq \frac{n}{2}$, centroid można wyszukać w czasie $\mathcal{O}(n)$.\\
Każde wywołanie zmniejsza nam drzewo conajmniej dwukrotnie, więc pełne drzewo będzie \\
\clearpage
\begin{python}
def getAns(l1, l2):
    sort(l1)

def solve(G):
    u = centroid(G)
    ans = 0
    red = []
    for r in G[u]:
        G2 = subtree(r)
        red.append(getRed(G2))
        ans += solve(G2)
    for (i,j) in list(combinations(range(3), 2)):
        ans += getAns(red[i],red[j])

dodaj_czarne(G)
\end{python}
\includepdf[page={1}]{L3Z05}
\clearpage
\subsection*{Zadanie 7.}
\subsection*{a)}
Zauważmy, że tak zadana macierz ma tylko $2n-1$ różnych elementów i wszystkie zanjdują się w pierwszej kolumnie i pierwszym wierszu (tam zaczyna się każda przekątna). Możemy więc macierz reprezentować jako wektor o rozmiarze \\$2n-1$ dodawanie dwóch macierzy możemy realizować przez dodawanie wektorów (przekątnę sie dodają). Stąd możemy je dodawać w $\mathcal{O}(n)$.
\subsection*{b)}
\textbf{Kluczowa obserwacja!}
Jeżeli $2 \mid n$ to macierz Teoplitz'a $A$ możemy zapiać:
\begin{align*}
A =
\begin{pmatrix}
\textbf{M} & N\\
P & \textbf{M}\\
\end{pmatrix}
\end{align*}
Gdzie każda z macierzy $M,N,P$ jest rozmiaru $\frac n 2 \times \frac n 2$.\\
Teraz gdy chcemy ją pomnożyć przez wektor
$v =
\begin{bmatrix}
u\\
w\\
\end{bmatrix}
$ gdzie $u,w$ to  odpowowiednio pierwsze i drugie $\frac n 2$ elementów wektora $v$. Dalej:
\begin{align*}
Av =
\begin{pmatrix}
\textbf{M} & N\\
P & \textbf{M}\\
\end{pmatrix} \cdot
\begin{bmatrix}
u\\
w\\
\end{bmatrix}
=
\begin{pmatrix}
Mu + Nw\\
Pu + Mw\\
\end{pmatrix}
=
\begin{pmatrix}
Mu + Nw + Mw - Mw\\
Pu + Mw + Mu - Mu\\
\end{pmatrix}\\
=
\begin{pmatrix}
\textbf{M(u+w)} + (N - M)w\\
\textbf{M(w+u)} + (P-M)u\\
\end{pmatrix}
\end{align*}
Widzimy więc, że możemy uzyskać wynik wykonując 3 mnożenia (macierz$\cdot$wektor) i 4 dodawania wektorów ($N,P,M$ możemy reprezentować jako wektor z \textbf{a})\\\\
W przypadku gdy $2 \nmid n$ musimy trochę pokombinować, żeby znaleźć \textit{te same} fragmenty macierzy $A$.\\
Okazuje się, że wystarczy podzielić macierz na środkową kolumną i środkowym wierszem:
\begin{align*}
A =
\begin{pmatrix}
\textbf{M} & d_1 & N\\
& d_2^T &\\
P & d_3 & \textbf{M}\\
\end{pmatrix}
\end{align*}
Wtedy mnożenie ma postać:
\begin{align*}
Av =
\begin{pmatrix}
\textbf{M} & d_1 & N\\
& d_2^T &\\
P & d_3 & \textbf{M}\\
\end{pmatrix} \cdot
\begin{bmatrix}
u\\
x\\
w\\
\end{bmatrix} =
\begin{pmatrix}
Mu + d_1x + Nw\\
d_2^T(u+x+w)\\
Pu + d_3x + Mw\\
\end{pmatrix}
=\\
\begin{pmatrix}
Mu + d_1x + Nw + Mw - Mu\\
d_2^Tv\\
Pu + d_3x + Mw + Mu - Mu\\
\end{pmatrix}=
\begin{pmatrix}
\textbf{M(u+w)} + d_1x + (N-M)w\\
d_2^Tv\\
u(P-M) + d_3x + \textbf{M(w+u)}\\
\end{pmatrix}
\end{align*}
W tym przypadku wykonujemy 3 mnożenia (macierz$\cdot$wektor), 3 dodawania wektorów i jeden iloczyn skalarny.\\
\clearpage
Stąd:
$$
T(n)=
\begin{cases}
1 & \text{gdy $n=1$}\\
\frac{n}{2} + 2\cdot(2\cdot\frac{n}{2}-1) + 2\cdot\frac{n}{2} + 3T(\frac n 2) = O(n) + 3T(\frac n 2)& \text{gdy $2\mid n$}\\
\frac{n-1}{2} + 2\cdot(2\cdot\frac{n-1}{2}-1) + 4\cdot(\frac{n-1}{2})+ 3T(\frac {n-1} 2) = O(n) + 3T(\frac {n-1} 2)& \text{gdy $2\nmid n$}\\
\end{cases}
$$
Stąd:
$$
T(n) = \Theta(n^{\log_2{3}}) \approx \Theta(n^{1.58})
$$
\clearpage
\subsection*{Zadanie. 8}
Możemy założyć, że w $A$ wszytskie liczby są różne. Możemy patrzeć tak przy porównywaniu: $T_{i,j}, T_{m,n}$:
$$
T_{i,j} < T_{m,n} \rightarrow i < m \rightarrow j < n
$$
\textbf{*} Zauważmy, że warunkiem wystarczającym na bycie medianą, jest bycię liczbą, która jest większa od $k\cdot\frac{n}{2}$ pozostałych elementów. (w nowym porządku)\\\\
Zakładamy, że rozwiązanie znajduje się na $i$-tej liście, możemy szukać konkretnego rozwiązania na tej liście używając binsearch'a.\\Liczba elementów mniejszych od $T_{i,k}$ jest większa od liczby elementów mniejszych od $T_{i,j}$ dla $k>j$. (Liczba elementów mniejszych zwiększa się z indeksem w każdej z tablic)\\\\
Teraz mając konkretnego kandydata na medianę, chcemy sprawdzić czy jest on nią, tj. czy spełnia \textbf{*}, policzyć od elementów . Możemy to też zrobić binsearch'em, w każdej z $k$ list szukając od ilu elementów nasz kandydat jest większy.
Jeżeli za mało przesuwamy się w \textit{prawo} a jak za dużo to w \textit{lewo}.\\\\
Sprawdzamy czy jest kandydat w każdej z $k$ list, szukanie w niej kandydata trwa $\log{n}$ sprawdzenie czy dana liczba jest medianą trwa $k\cdot \log{n}$ (w każdej tablicy binsearch). Stąd $\mathcal{O}(k^2\log^2{n})$
\clearpage
\begin{python}
# zakladamy juz nowy porzadek
Ts = [] # tablica tablic
n = len(Ts[0])

def getSmaller(elm, T):
    l = 0
    r = n-1
    while l < r:
        mid = (l+r)//2
        if T[mid] < elm:
            l = mid
        else:
            r = mid - 1
    return l

def checkCandidate(elm):
    smaller = 0
    for T in Ts:
        smaller+=getSmaller(elm, T)
    if smaller < n//2:
        return -1
    if smaller > n//2:
        return 1
    return 0


for i in range(k):
    l = 0
    r = n-1
    while l < r:
        mid = (l+r)//2
        if checkCandidate(Ts[mid]) == 1:
            r = mid - 1
        if checkCandidate(Ts[mid]) == -1:
            l = mid + 1
        if checkCandidate(Ts[mid]) == 0:
            return mid
\end{python}
\end{document}

