{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkKY6us_cCg4"
   },
   "source": [
    "# Homework 1\n",
    "\n",
    "**For exercises in the week 19-23.10.20**\n",
    "\n",
    "**Points: 7 + 3 bonus point**\n",
    "\n",
    "Please solve the problems at home and bring to class a [declaration form](http://ii.uni.wroc.pl/~jmi/Dydaktyka/misc/kupony-klasyczne.pdf) to indicate which problems you are willing to present on the backboard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PMPpxChQHnR"
   },
   "source": [
    "## Problem 1 [1p]\n",
    "Let $v\\in\\mathbb{R}^D$ be a vector. Define the gradient of $f(v)\\in\\mathbb{R}$ with respect to $v$ to be $\\frac{\\partial f}{\\partial v} = \\left[\\frac{\\partial f(v)}{\\partial v_1}, \\frac{\\partial f(v)}{\\partial v_2}, ..., \\frac{\\partial f(v)}{\\partial v_D}\\right]$\n",
    "\n",
    "Find the gradients of the following functions with respect to vector $[x, y, z]^T$:\n",
    "1. $f_1([x, y, z]^T) = x + y [1,1,0]$\n",
    "2. $f_2([x, y, z]^T) = xy$\n",
    "3. $f_3([x, y, z]^T) = x^2y^2$\n",
    "4. $f_4([x, y, z]^T) = (x + y)^2$\n",
    "5. $f_5([x, y, z]^T) = x^4 + x^2 y z + x y^2 z + z^4$\n",
    "6. $f_6([x, y, z]^T) = e^{x + 2y}$\n",
    "7. $f_7([x, y, z]^T) = \\frac{1}{x y^2}$\n",
    "8. $f_8([x, y, z]^T) = ax + by + c$\n",
    "9. $f_9([x, y, z]^T) = \\tanh(ax + by + c)$\\\\\\\\\n",
    "1. $\\nabla f_1([x, y, z]^T) = [1,1,0]^T$\n",
    "2. $\\nabla f_2([x, y, z]^T) = [y,x,0]^T$\n",
    "3. $\\nabla f_3([x, y, z]^T) = [2yx^2,2y^2x,0]^T$\n",
    "4. $\\nabla f_4([x, y, z]^T) = [2x + 2y, 2x + 2y,0]^T$\n",
    "5. $\\nabla f_5([x, y, z]^T) = [4x^3 + 2xyz + y^2z, x^2z + 2xyz, x^2y + xy^2 + 4z^3]^T$\n",
    "6. $\\nabla f_6([x, y, z]^T) = [e^{x + 2y},2e^{x + 2y},0]^T$\n",
    "7. $\\nabla f_7([x, y, z]^T) = [\\frac{-1}{x^2 y^2}, \\frac{-2}{x y^3},0]^T$\n",
    "8. $\\nabla f_8([x, y, z]^T) = [a,b,0]^T$\n",
    "9. $\\nabla f_9([x, y, z]^T) = [a sech^2(c + a x + b y), b sech^2(c + a x + b y),0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TH9nPvyCMu27"
   },
   "source": [
    "## Problem 2 [0.5p]\n",
    "\n",
    "Find the gradients or Jacobians of the following functions with respect to vector $\\mathbf{x}$, where $\\mathbf{x}, \\mathbf{b} \\in \\mathbb{R}^{n}$, $\\mathbf{W} \\in \\mathbb{R}^{n \\times n}$:\n",
    "\n",
    "1. $\\mathbf{W} \\mathbf{x} + \\mathbf{b} $ <br>\n",
    "$dy = d(Wx + b) = d\\left(\\sum_{j=1}^n(\\sum_{i=1}^n w_{i,j}x_{j} + b)\\right) = \\sum_{j=1}^n(\\sum_{i=1}^n d(w_{i,j}x_{j} + b)) = \\left(\\sum_{j=1}^n(\\sum_{i=1}^n w_{i,j})\\right) = W\n",
    "$\n",
    "2. $\\mathbf{x}^T \\mathbf{W} \\mathbf{x} $\n",
    "$dy\n",
    " = d(x^{T}Wx)\n",
    "= d(Wx\\cdot x)\n",
    "= d\\left(\\sum_{i=1}^{n}(Wx)_{i}x_{i}\\right) \\\\\n",
    " = d \\left(\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{i,j}x_{j}x_{i}\\right)\n",
    "=\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{i,j}x_{i}dx_{j}+\\sum_{i=1}^{n}\\sum_{j=1}^{n}w_{i,j}x_{j}dx_{i} \\\\\n",
    " =\\sum_{i=1}^{n}(Wx)dx_{i}+\\sum_{i=1}^{n}(Wdx)x_{i}\n",
    "=(dx)^{T}Wx+x^{T}Wdx \\\\\n",
    " =(dx)^{T}Wx+(dx)^{T}W^{T}x\n",
    "=(dx)^{T}(W+W^{T})x.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rdqrcVvNTv0"
   },
   "source": [
    "## Problem 3 [1p]\n",
    "\n",
    "Let $(x^{(i)},y^{(i)})$ be a data sample with $x^{(i)}\\in\\mathbb{R}^{1\\times D}$, $y^{(i)}\\in\\mathbb{R}^{1\\times 1}$ and $\\Theta \\in\\mathbb{R}^{D \\times 1}$ be a parameter vector.\n",
    "\n",
    "Find the closed form solution $\\Theta^*$ to \n",
    "\n",
    "$$\n",
    "\\min_\\Theta J (\\Theta) =\n",
    "\\min_\\Theta \\left(\\frac{1}{2}\\sum_i (x^{(i)}\\Theta - y^{(i)})^2 + \\frac{\\lambda}{2}\\sum_{d=1}^D \\Theta_d^2\\right).\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J (\\Theta)}{\\partial \\Theta} = \\frac{1}{2}\\sum_i \\frac{\\partial}{\\partial \\Theta} ((x_i\\Theta - y_i)^T(x_i\\Theta - y_i)) + \\frac{\\lambda}{2}\\frac{\\partial}{\\partial \\Theta}\\Theta^T\\Theta = \\\\\n",
    " =\\sum_i x_i^T(x_i\\Theta - y_i) + \\lambda\\Theta\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\Theta_* = \\frac{\\sum_i x_i^Ty_i}{\\sum_i x_i^Tx_i + \\lambda}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72HwrFKBb9Mn"
   },
   "source": [
    "## Problem 4 [1.5p]\n",
    "\n",
    "Given observations $x_1,\\ldots,x_n$\n",
    "  coming from a certain distribution,\n",
    "  prove that MLE of a particular parameter of that distribution is equal to the sample mean $\\frac{1}{n}\\sum_{i=1}^n x_i$:\n",
    "1. Bernoulli distribution with success probability $p$ and MLE $\\hat{p}$,\n",
    "2. Gaussian distribution $\\mathcal{N}(\\mu,\\sigma)$ and MLE $\\hat{\\mu}$,\n",
    "3. Poisson distribution $\\mathit{Pois}(\\lambda)$ and MLE $\\hat{\\lambda}$.\n",
    "\n",
    "$\\checkmark handwritten$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1RPYxxGdSAE"
   },
   "source": [
    "## Problem 5 [1p]\n",
    "\n",
    "Show that the Median is the MLE estimator of the _location_ $\\mu$ of the [Laplace distribution](https://en.wikipedia.org/wiki/Laplace_distribution).\n",
    "\n",
    "What loss function is induced by the Laplace distribution?\n",
    "\n",
    "$\\checkmark handwritten$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kxgvhPBb7hN"
   },
   "source": [
    "## Problem 6 [1p]\n",
    "\n",
    "Bayes' theorem allows to reason about conditional probabilities of causes and their effects:\n",
    "\n",
    "\\begin{equation}\n",
    "p(A,B)=p(A|B)p(B)=p(B|A)p(A)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "p(A|B) = \\frac{p(B|A)p(A)}{p(B)}\n",
    "\\end{equation}\n",
    "\n",
    "Bayes' theorem allows us to reason about probabilities of causes, when\n",
    "we observe their results.  Instead of directly answering the hard\n",
    "question $p(\\text{cause}|\\text{effect})$ we can instead separately\n",
    "work out the marginal probabilities of causes $p(\\text{cause})$ and\n",
    "carefully study their effects $p(\\text{effect}|\\text{cause})$.\n",
    "\n",
    "Solve the following using Bayes' theorem.\n",
    "\n",
    "1. There are two boxes on the table: box \\#1 holds two\n",
    "  black balls and eight red ones, box \\#2 holds 5 black ones and\n",
    "  5 red ones. We pick a box at random (with equal probabilities),\n",
    "  and then a ball from that box.\n",
    "  1. What is the probability, that the\n",
    "  ball came from box \\#1 if we happened to pick a red ball?\n",
    "  \n",
    "1. The government has started a preventive program of\n",
    "  mandatory tests for the Ebola virus. Mass testing method is\n",
    "  imprecise, yielding 1% of false positives (healthy, but the test\n",
    "  indicates the virus) and 1% of false negatives (having the virus\n",
    "  but healthy according to test results).\n",
    "  As Ebola is rather infrequent, lets assume that it occurs in\n",
    "  one in a million people in Europe.\n",
    "  1. What is the probability,\n",
    "  that a random European, who has tested positive for Ebola\n",
    "  virus, is indeed a carrier?\n",
    "  2. Suppose we have an additional information, that the person has just\n",
    "  arrived from a country where one in a thousand people is a carrier.\n",
    "  How much will be the increase in probability?\n",
    "  3. How accurate should be the test for a 80% probability of true\n",
    "  positive in a European?\n",
    "  \n",
    "  \n",
    "$\\checkmark handwritten$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEETFqdrqBoj"
   },
   "source": [
    "## Problem 7 (Kohavi) [1p]\n",
    "\n",
    "(The failure of leave-one-out evaluation.) Consider a binary classification dataset in which the labels are assigned completely at random, with 50% probability given to either class. Assume you have collected a dataset with 100 records in which exactly 50 of them belong to class 0 and 50 to class 1. \n",
    "\n",
    "What will be the leave-one-out accuracy of the majority voting classifier?\n",
    "\n",
    "NB: sometimes it is useful to equalize the number of classes in each fold of cross-validation, e.g. using the [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) implementation from SKlearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick   $C_0$\n",
    "$$\n",
    "major  (\\underbrace{C_0, \\dots, C_0}_{49}, \\overbrace{C_1 \\dots C_1}^{50}) = C_1\n",
    "$$\n",
    "\n",
    "thus leave-one-out calssify:\n",
    "\n",
    "$$\n",
    "C_0 \\rightarrow C_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrnFTXpfcN1R"
   },
   "source": [
    "## Problem 8 [1pb]\n",
    "Do Problem 6.1 from [Assignment 1](https://github.com/janchorowski/ml_uwr/blob/fall2019/assignment1/Assignment1.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PO62-Ffy6z9"
   },
   "source": [
    "## Problem 9 [1bp]\n",
    "\n",
    "Many websites ([Reddit](reddit.com), [Wykop](wykop.pl), [StackOverflow](stackoverflow.com)) provide sorting of comments based on user votes. Discuss what are the implications when sorting by:\n",
    "- difference between up- and down-votes\n",
    "- mean score\n",
    "- lower or upper confidence bound of the score\n",
    "\n",
    "At least for Reddit the sorting algorithm can be found online, what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHOYUVyoLdN6"
   },
   "source": [
    "## Problem 10 [1bp]\n",
    "Find informations about the Literary Digest poll for the 1936 election. Discuss what errors were made and how they can apply also to today's polls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q54xMuOWWsX7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
